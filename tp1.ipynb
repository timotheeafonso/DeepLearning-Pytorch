{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TE2ItlsI956"
   },
   "source": [
    "# Deep Learning - Introduction à Pytorch \n",
    "\n",
    "\n",
    "## TP1 : Prise en main de Pytorch\n",
    "\n",
    "Sylvain Lamprier (sylvain.lamprier@univ-angers.fr)\n",
    "\n",
    "Supports adaptés de Nicolas Baskiotis (nicolas.baskiotis@sorbonne-univeriste.fr) et Benjamin Piwowarski (benjamin.piwowarski@sorbonne-universite.fr) -- MLIA/ISIR, Sorbonne Université"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAER7frwJu9L"
   },
   "source": [
    "\n",
    "\n",
    "Les lignes suivantes permettent d'importer pytorch et vérifier qu'un GPU est disponible. Il est recommandé d'utiliser un manager d'environnement python type conda pour l'ensemble des tps. Après la création de votre environnement (via  $\\texttt{conda create --name <nom_env>}$) et son activation (via $\\texttt{conda activate <nom_env>}$), installer pytorch selon la commande donnée sur le site de $\\href{https://pytorch.org/}{\\texttt{PyTorch}}$  (choisir la version en fonction de votre GPU et sa version de cuda).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3Y9YOOHHhJKY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La version de torch est :  2.1.1+cu121\n",
      "Le calcul GPU est disponible ?  False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"La version de torch est : \",torch.__version__)\n",
    "print(\"Le calcul GPU est disponible ? \", torch.cuda.is_available())\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2LqFo3wzwYP"
   },
   "source": [
    "### <span class=\"alert-success\"> Exercice : Syntaxe\n",
    "\n",
    "Le principal objet manipulé sous Pytorch est **torch.Tensor** qui correspond à un tenseur mathématique (généralisation de la notion de matrice en $n$-dimensions), très proche dans l'utilisation de **numpy.array**.   Cet objet est optimisé pour les calculs sur GPU ce qui implique quelques contraintes plus importantes que sous **numpy**. En particulier :\n",
    "* le type du tenseur manipulé est très important et les conversions ne sont pas automatique (**FloatTensor** de type **torch.float**, **DoubleTensor** de type **torch.double**,  **ByteTensor** de type **torch.byte**, **IntTensor** de type **torch.int**, **LongTensor** de type **torch.long**). Pour un tenseur **t** La conversion se fait très simplement en utilisant les fonctions : **t.double()**, **t.float()**, **t.long()** ...\n",
    "* la plupart des opérations ont une version *inplace*, c'est-à-dire qui modifie le tenseur plutôt que de renvoyer un nouveau tenseur; elles sont suffixées par **_** (**add_** par exemple).\n",
    "\n",
    "Donner des exemples d'instructions correspondant aux commentaires ci-dessous. N'hésitez pas à vous référez à la [documentation officielle](https://pytorch.org/docs/stable/tensors.html) pour la liste exhaustive des opérations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "code",
    "id": "VZxNfy1b1u43",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenseur initial (a) de forme (2, 3, 4):\n",
      "tensor([[[0.6455, 0.4800, 0.5191, 0.0370],\n",
      "         [0.1434, 0.8538, 0.3923, 0.6463],\n",
      "         [0.9143, 0.5898, 0.8275, 0.5068]],\n",
      "\n",
      "        [[0.9707, 0.9236, 0.4069, 0.8437],\n",
      "         [0.7572, 0.1162, 0.1703, 0.0508],\n",
      "         [0.9121, 0.6073, 0.7591, 0.8040]]])\n",
      "Tenseur final:\n",
      "tensor([[[0.6455, 0.4800, 0.5191, 0.0370],\n",
      "         [0.1434, 0.8538, 0.3923, 0.6463],\n",
      "         [0.9143, 0.5898, 0.8275, 0.5068]],\n",
      "\n",
      "        [[0.6455, 0.4800, 0.5191, 0.0370],\n",
      "         [0.1434, 0.8538, 0.3923, 0.6463],\n",
      "         [0.9143, 0.5898, 0.8275, 0.5068]],\n",
      "\n",
      "        [[0.6455, 0.4800, 0.5191, 0.0370],\n",
      "         [0.1434, 0.8538, 0.3923, 0.6463],\n",
      "         [0.9143, 0.5898, 0.8275, 0.5068]],\n",
      "\n",
      "        [[0.9707, 0.9236, 0.4069, 0.8437],\n",
      "         [0.7572, 0.1162, 0.1703, 0.0508],\n",
      "         [0.9121, 0.6073, 0.7591, 0.8040]],\n",
      "\n",
      "        [[0.9707, 0.9236, 0.4069, 0.8437],\n",
      "         [0.7572, 0.1162, 0.1703, 0.0508],\n",
      "         [0.9121, 0.6073, 0.7591, 0.8040]],\n",
      "\n",
      "        [[0.9707, 0.9236, 0.4069, 0.8437],\n",
      "         [0.7572, 0.1162, 0.1703, 0.0508],\n",
      "         [0.9121, 0.6073, 0.7591, 0.8040]]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]) tensor([0., 0., 0., 0., 0.])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]]) tensor([[0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Création de tenseurs et caractéristiques\n",
    "## Créer un tenseur (2,3) à partir d'une liste\n",
    "t1=torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))\n",
    "\n",
    "## Créer un tenseur  tenseur rempli de 1 de taille 2x3x4\n",
    "t2 = torch.ones([2,3,4])\n",
    "\n",
    "## tenseur de zéros de taille 2x3 de type float\n",
    "t3 = torch.zeros([2,3,4],dtype=torch.float)\n",
    "\n",
    "## tirage uniforme entier entre 10 et 15, \n",
    "## remarquez l'utilisation du _ dans random pour l'opération inplace\n",
    "t4 = torch.empty([2, 3],dtype=torch.int32).random_(10,16)\n",
    "\n",
    "## tirage suivant la loi normale\n",
    "t5 = torch.empty([3, 4],dtype=torch.float32).normal_()\n",
    "\n",
    "## equivalent à zeros(3,4).normal_\n",
    "t6 = torch.randn([3, 4])\n",
    "\n",
    "## Création d'un vecteur de 3 flottants selon la loi de normale\n",
    "t7 = torch.randn([1, 3])\n",
    "\n",
    "## concatenation de tenseurs sur la dimension 0\n",
    "t8_1 = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))\n",
    "t8_2 = torch.tensor(np.array([[7, 8, 9], [10,11,12]]))\n",
    "t8 = torch.cat((t8_1,t8_2),0)\n",
    "\n",
    "## concatenation de tenseurs  sur la dimension 1\n",
    "t9_1 = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))\n",
    "t9_2 = torch.tensor(np.array([[7, 8, 9], [10,11,12]]))\n",
    "t9 = torch.cat((t9_1,t9_2),1)\n",
    "\n",
    "## Taille des tenseurs/vecteurs\n",
    "t10 = torch.zeros([2,3,4],dtype=torch.float)\n",
    "taille = t10.shape\n",
    "\n",
    "## Conversion de type\n",
    "t11 = torch.ones([2,3,4],dtype=torch.float)\n",
    "t11_int = t11.to(torch.int32)\n",
    "\n",
    "# Opérations élémentaires sur les tenseurs\n",
    "## produit scalaire (et contrairement à numpy, que produit scalaire)\n",
    "t12_1 = torch.tensor([1, 2, 3])\n",
    "t12_2 = torch.tensor([4, 5, 6])\n",
    "t12 = torch.dot(t12_1, t12_2)\n",
    "\n",
    "## produit matriciel : utilisation de @ ou de la fonction mm\n",
    "t13_1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t13_2 = torch.tensor([[7, 8], [9, 10], [11, 12]])\n",
    "t13 = t13_1@t13_2\n",
    "\n",
    "## transposé\n",
    "t14_1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t14 = t14_1.t()\n",
    "\n",
    "## index du maximum selon une dimension\n",
    "t15 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "max_values, max_indices = torch.max(t15, dim=1)\n",
    "\n",
    "## somme selon une dimension/de tous les éléments\n",
    "t16 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "somme = torch.sum(t16,dim=1)\n",
    "\n",
    "## moyenne selon  une dimension/sur tous les éléments\n",
    "t17 = torch.tensor([[1, 2, 3], [4, 5, 12]]).float().mean(dim=1)\n",
    "\n",
    "## changer les dimensions du tenseur (la taille totale doit être inchangée)\n",
    "t18 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t_resized = t18.view(3, 2) \n",
    "\n",
    "## somme/produit/puissance termes a termes\n",
    "t19_1 = torch.tensor([1, 2, 3])\n",
    "t19_2 = torch.tensor([4, 5, 6])\n",
    "\n",
    "sum_result = t19_1 + t19_2\n",
    "product_result = t19_1 * t19_2\n",
    "puiss_result = t19_1**2\n",
    "#print(\"sum \"+str(sum_result)+\" poduct \"+str(product_result)+\" puiss \"+str(puiss_result))\n",
    "\n",
    "## Soit un tenseur a de (2,3,4). Le recopier dans une version (2,3,3,4) avec les tenseurs (3,4) \n",
    "## a[0] et a[1] recopiés chacun 3 fois (avec expand)\n",
    "# Créer le tenseur initial a de forme (2, 3, 4)\n",
    "a = torch.rand((2,3,4))\n",
    "print(\"Tenseur initial (a) de forme (2, 3, 4):\")\n",
    "print(a)\n",
    "# Créer les tenseurs (3, 4)\n",
    "a=a.view(2,1,3,-1).expand(-1,3,-1,-1).contiguous().view(-1,3,4)\n",
    "print(\"Tenseur final:\")\n",
    "print(a)\n",
    "# Recopier avec expand\n",
    "\n",
    "# Afficher les résultats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## attention ! comme sous numpy, il peut y avoir des pièges ! \n",
    "## Vérifier toujours les dimensions !!\n",
    "a=torch.zeros(5,1)\n",
    "b = torch.zeros(5)\n",
    "print(a,b)\n",
    "## la première opération fait un broadcast et le résultat est 1 tenseur à 2 dimensions,\n",
    "## le résultat de la deuxième opération est une matrice contenant un vecteur unique\n",
    "print(a-b,a.t()-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span class=\"alert-success\"> Exercice :   Régression linéaire  </span>\n",
    "\n",
    "On souhaite apprendre un modèle de régression linéaire $f$ du type:  $f(x,w,b)=x.w^t+b$  avec $x\\in \\mathbb{R}^{{d}}$ un vecteur d'observations pour lequel on souhaite prédire une sortie $\\hat{y} \\in \\mathbb{R}$, $w\\in\\mathbb{R}^{1,d}$ et $b\\in \\mathbb{R}$ les paramètres du modèle. \n",
    "\n",
    "Pour cela on dispose d'un jeu de données étiquetées $\\{(x,y)\\}$, que l'on découpe en jeu d'entraînement (80%) et de validation (20%). Dans cet exercice, on utilisera le jeu de données très classique *Boston*, le prix des loyers à Boston en fonction de caractéristiques socio-économiques des quartiers.\n",
    "\n",
    "On considèrera un coût moindres carrés pour apprendre le modèle sur le jeu d'entraînement (avec $N$ le nombre de données d'entraînement et $(x^i,y^i)$ le i-ème couple de cet ensemble): $$w^∗,b^∗=argmin_{w,b}\\frac{1}{N} \\sum_{i=1}^N \\|f(x^i,w,b)-y^i\\|^2$$\n",
    "\n",
    "\n",
    "* Définir (en version tensorielle PyTorch) la fonction **flineaire(x,w,b)** qui calcule $f(x,w,b)=x.w^t+b$  avec $x\\in \\mathbb{R}^{{n\\times d}},~w\\in\\mathbb{R}^{1,d}, b\\in \\mathbb{R}$\n",
    "* Donner le code d'une fonction **loss(x,w,b,y)** qui retourne le coût moindre carré du modèle linéaire utilisant **flineaire(x,w,b)** pour un batch de données $x$ et leurs images associées $y$. \n",
    "* Calculer le gradient de l'erreur en fonction de chacun des paramètres $w_i$ et b. Donner le code d'une fonction **getGradient(x,w,b)** (commencer éventuellement avec des boucles avant de réaliser la version matricielle plus efficace). \n",
    "* Complétez le code ci-dessous pour réaliser une descente de gradient et apprendre les paramètres optimaux de la regression linéaire.\n",
    "* Modifier le code ci-dessous pour n'entraîner que sur 80% des données et se tester sur 20%\n",
    "\n",
    "\n",
    "\n",
    "Attention ! \n",
    "* l'algorithme doit converger avec la valeur de epsilon fixée; si ce n'est pas le cas, il y a une erreur (la plupart du temps au niveau du calcul du coût)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flineaire(x,w,b):\n",
    "    return (x@w.T) + b\n",
    "\n",
    "def getLoss(x,w,b,y):\n",
    "    y = y.view(-1,1) # n ligne et 1 colonne\n",
    "    return torch.pow(flineaire(x,w,b)-y,2).mean()/2.0 # pow -> puissance\n",
    "\n",
    "def getGradient(x, w, b, y):\n",
    "    # Calcul de la prédiction\n",
    "    y = y.view(-1,1)\n",
    "    yhat = flineaire(x,w,b)\n",
    "    diff = yhat - y    \n",
    "    '''\n",
    "    #version boucle\n",
    "    g= torch.zeros_like(w)\n",
    "    for i in range(w.size(-1)):\n",
    "        g[0,i] = (x[:,i].view(-1,1)*diff.mean())\n",
    "    return g, diff.mean()\n",
    "    '''\n",
    "    return ((x.t()@diff)/x.shape[0]).t(),(diff.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-22f0abb9b488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Chargement des données California et transformation en tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_california_housing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhousing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_california_housing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## chargement des données\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhousing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhousing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sklearn/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_lfw\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_lfw_pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_lfw\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_lfw_people\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_twenty_newsgroups\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_20newsgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_twenty_newsgroups\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_20newsgroups_vectorized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_openml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sklearn/datasets/_twenty_newsgroups.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_fetch_remote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRemoteFileMetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sklearn/feature_extraction/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_dict_vectorizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_hash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureHasher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_to_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_to_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sklearn/feature_extraction/image.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m def grid_to_graph(n_x, n_y, n_z=1, *, mask=None, return_as=sparse.coo_matrix,\n\u001b[0;32m--> 172\u001b[0;31m                   dtype=np.int):\n\u001b[0m\u001b[1;32m    173\u001b[0m     \"\"\"Graph of the pixel-to-pixel connections\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__former_attrs__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__former_attrs__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'testing'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "## Chargement des données California et transformation en tensor.\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing() ## chargement des données\n",
    "data_x = torch.tensor(housing['data'],dtype=torch.float)\n",
    "data_y = torch.tensor(housing['target'],dtype=torch.float)\n",
    "\n",
    "print(\"Nombre d'exemples : \",data_x.size(0), \"Dimension : \",data_x.size(1))\n",
    "print(data_x,data_y)\n",
    "\n",
    "torch.random.manual_seed(1)\n",
    "\n",
    "#initialisation aléatoire de w et b\n",
    "w = torch.randn(1,data_x.size(1),requires_grad=True)\n",
    "b =  torch.randn(1,1,requires_grad=True)\n",
    "\n",
    "#decoupage en train 80 et test 20\n",
    "train_x = data_x[:int(data_x.size(0)*0.8)]\n",
    "train_y = data_y[:int(data_y.size(0)*0.8)]\n",
    "\n",
    "test_x = data_x[int(data_x.size(0)*0.8):]\n",
    "test_y = data_y[int(data_y.size(0)*0.8):]\n",
    "\n",
    "print(\"Nombre d'exemples train : \",train_x.size(0), \"Dimension : \",train_x.size(0),\"x\",train_x.size(1))\n",
    "print(\"Nombre d'exemples test : \",test_x.size(0), \"Dimension : \",test_x.size(0),\"x\",test_x.size(1))\n",
    "\n",
    "\n",
    "EPOCHS = 100000\n",
    "EPS = 1e-7\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    grad_w,grad_b = getGradient(train_x,w,b,train_y)\n",
    "\n",
    "    w = w - EPS*grad_w\n",
    "    b = b - EPS*grad_b\n",
    "\n",
    "    loss = getLoss(train_x,w,b,train_y)\n",
    "    \n",
    "    if i%10000==0:\n",
    "        print(\"Epoch : \",i,\" Loss : \",loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DeepLearning fc TP1 2020-2021-correction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
